{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from jupyterthemes import jtplot\n",
    "import os\n",
    "jtplot.style()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AMD.csv\")\n",
    "data = df.Open.values\n",
    "data = data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.80)\n",
    "test_size = len(data) - train_size\n",
    "train, test = data[0:train_size], data[train_size:len(data)]\n",
    "train, test = np.reshape(train, (-1, 1)), np.reshape(test, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(X=train)\n",
    "test = scaler.transform(X=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an additional column with values at time T=t+1\n",
    "def create_dataset(dataset, step=1):\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - 1 - step):\n",
    "        dataX.append(dataset[i])\n",
    "        dataY.append(dataset[i + step])\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = create_dataset(train, 1)\n",
    "testX, testY = create_dataset(test, 1)\n",
    "trainX = np.reshape(trainX, (-1, 1))\n",
    "trainY = np.reshape(trainY, (-1,))\n",
    "testX = np.reshape(testX, (-1, 1))\n",
    "testY = np.reshape(testY, (-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks = trainX.shape[1]\n",
    "# placeholders\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_stocks])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neurons\n",
    "n_neurons_1 = 1024\n",
    "n_neurons_2 = 512\n",
    "n_neurons_3 = 256\n",
    "n_neurons_4 = 128\n",
    "n_target = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode='fan_avg', distribution='uniform', scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_stocks, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "# Layer 2\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "# Layer 3\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "# Layer 4\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, n_target]))\n",
    "bias_out = tf.Variable(bias_initializer([n_target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "# Session\n",
    "net = tf.Session()\n",
    "net.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs and batch size\n",
    "epochs = 10\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_train = np.array([])\n",
    "mse_test = np.array([])\n",
    "for e in range(epochs):\n",
    "    # shuffle data\n",
    "    indices = np.random.permutation(np.arange(len(trainY)))\n",
    "    trainX = trainX[indices]\n",
    "    trainY = trainY[indices]\n",
    "\n",
    "    for i in range(0, len(trainY) // batch_size):\n",
    "        start = i * batch_size\n",
    "        batch_x = trainX[start:start + batch_size]\n",
    "        batch_x = np.reshape(batch_x, (-1, 1))\n",
    "        batch_y = trainY[start:start + batch_size]\n",
    "        batch_y = np.reshape(batch_y, (-1,))\n",
    "        net.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        if np.mod(i, 2) == 0:\n",
    "            mse_train = np.append(mse_train, net.run(mse, feed_dict={X: trainX, Y: trainY}))\n",
    "            mse_test = np.append(mse_test, net.run(mse, feed_dict={X: testX, Y: testY}))\n",
    "            pred = net.run(out, feed_dict={X: testX})\n",
    "            plt.plot(testY, label='testY')\n",
    "            plt.plot(np.reshape(pred, (-1, 1)), label='prediction')\n",
    "            plt.legend()\n",
    "            plt.title('Epoch ' + str(e) + ', Batch ' + str(i))\n",
    "            if not os.path.exists('plots'):\n",
    "                os.mkdir('plots')\n",
    "            file_name = 'plots/epoch_' + str(e) + '_batch_' + str(i) + '.png'\n",
    "            plt.savefig(file_name)\n",
    "            plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train :  0.022356826812028885\n",
      "MSE test :  0.02710242196917534\n"
     ]
    }
   ],
   "source": [
    "print('MSE train : ', mse_train[-1])\n",
    "print('MSE test : ', mse_test[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
